{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#POS-tagging\" data-toc-modified-id=\"POS-tagging-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>POS tagging</a></span></li><li><span><a href=\"#Chunking\" data-toc-modified-id=\"Chunking-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Chunking</a></span></li><li><span><a href=\"#NER-tagging\" data-toc-modified-id=\"NER-tagging-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>NER tagging</a></span></li><li><span><a href=\"#Supersense-tagging\" data-toc-modified-id=\"Supersense-tagging-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Supersense tagging</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf ../data/processed/NER\n",
    "! rm -rf ../data/processed/POS\n",
    "! rm -rf ../data/processed/CHUNKING\n",
    "! rm -rf ../data/processed/SUPERSENSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DRIVE_PATH = \"G:/AzureBackup/\"\n",
    "OUTPUT_DIRECTORY = \"../data/processed/\"\n",
    "SEQ_SPLITTER = re.compile(r'\\n\\s*\\n', flags=re.M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conll_data(filename, ncols=2):\n",
    "    with open(filename, encoding='utf-8') as fp:\n",
    "        for seq in SEQ_SPLITTER.split(fp.read()):\n",
    "            seq_ = []\n",
    "            for line in seq.splitlines():\n",
    "                line = line.rstrip()\n",
    "                if not line:\n",
    "                    continue\n",
    "                values = line.split(\"\\t\")\n",
    "                if len(values) < ncols:\n",
    "                    # Skip invalid lines\n",
    "                    continue\n",
    "                seq_.append(values)\n",
    "            if not seq_:\n",
    "                seq_ = []\n",
    "                continue\n",
    "            yield seq_\n",
    "        \n",
    "def sequence2str(seq):\n",
    "    return \"\\n\".join([\n",
    "        \"\\t\".join(line)\n",
    "        for line in seq\n",
    "    ])\n",
    "        \n",
    "def write_conll_data(sequences, filename):\n",
    "    with open(filename, \"w+\", encoding='utf-8') as fp:\n",
    "        for seq in sequences:\n",
    "            seq_str = sequence2str(seq)\n",
    "            print(seq_str, end=\"\\n\\n\", file=fp)\n",
    "    \n",
    "def parse_label(label):\n",
    "    return label.upper()\n",
    "\n",
    "def clean_label(label):\n",
    "    if not label:\n",
    "        label = \"O\" \n",
    "    return parse_label(label)\n",
    "\n",
    "DIMSUM_PREFIX_MAP = {\"N\": \"NOUN\", \"V\": \"VERB\"}\n",
    "def clean_dimsum_label(label):\n",
    "    if label:\n",
    "        prefix, label = label.upper().split(\".\")\n",
    "        prefix = DIMSUM_PREFIX_MAP.get(prefix, prefix)\n",
    "        label = \"{}.{}\".format(prefix, label)\n",
    "    return clean_label(label)\n",
    "\n",
    "POS_MAP = {\"PRT\": \"PART\", \".\": \"PUNCT\", \"CONJ\": \"CCONJ\", \"VPP\": \"VBP\"} # CONJ in Foster and DimSum should be CCONJ\n",
    "def clean_pos_label(label):\n",
    "    if label:\n",
    "        label = POS_MAP.get(label, label)\n",
    "    return clean_label(label)\n",
    "\n",
    "def clean_ner_label(label):\n",
    "    label = label.split(\".\")\n",
    "    if len(label) == 2:\n",
    "        label = \"{}-{}\".format(label[0].split(\"-\")[0], '.'.join(label[1:]))\n",
    "    else:\n",
    "        label = \".\".join(label)\n",
    "    return clean_label(label)\n",
    "    \n",
    "def extract_token_labels(seq, token_idx=0, label_idx=1, parse_label=parse_label):\n",
    "    return [(line[token_idx], parse_label(line[label_idx])) for line in seq]\n",
    "    \n",
    "def get_stats(sequences, token_idx=0, label_idx=1):\n",
    "    stats = {\n",
    "        \"sequences\": len(sequences),\n",
    "        \"total_tokens\": 0\n",
    "    }\n",
    "    token_vocab = Counter()\n",
    "    label_vocab = Counter()\n",
    "    for seq in sequences:\n",
    "        stats[\"total_tokens\"] += len(seq)\n",
    "        for row in seq:\n",
    "            token_vocab[row[token_idx].upper()] += 1\n",
    "            label_vocab[row[label_idx].upper()] += 1\n",
    "    for key, vocab in [\n",
    "        (\"tokens\", token_vocab),\n",
    "        (\"labels\", label_vocab)\n",
    "    ]:\n",
    "        stats[\"{}_vocab\".format(key)] = vocab\n",
    "        stats[\"{}_unique\".format(key)] = len(vocab.keys())\n",
    "    return stats \n",
    "    \n",
    "def process_file(input_files, output_file, token_idx=0, label_idx=1, parse_label=parse_label):\n",
    "    if isinstance(input_files, str):\n",
    "        input_files = [input_files]\n",
    "    sequences = []\n",
    "    for input_file in input_files:\n",
    "        # replace datadrive path with current data drive\n",
    "        input_file = input_file.replace(\"/datadrive/\", \"\")\n",
    "        input_file = os.path.join(DATA_DRIVE_PATH, input_file)\n",
    "        for seq in read_conll_data(input_file):\n",
    "            seq = extract_token_labels(seq, token_idx, label_idx, parse_label)\n",
    "            sequences.append(seq)\n",
    "    # get stats\n",
    "    stats = get_stats(sequences)\n",
    "    write_conll_data(sequences, output_file)\n",
    "    return stats\n",
    "    \n",
    "def split_label(label):\n",
    "    if label == \"O\":\n",
    "        boundary = label\n",
    "        label = None\n",
    "    else:\n",
    "        boundary, label = label.split(\"-\", 1)\n",
    "    return boundary, label\n",
    "    \n",
    "def gather_data(files, task_name, split_boundary=False, token_idx=0, label_idx=1, parse_label=parse_label, stats_data=None):\n",
    "    if stats_data is None:\n",
    "        stats_data = []\n",
    "    for key, data_dict in files.items():\n",
    "        for split_prefix, input_files in data_dict.items():\n",
    "            #input_file = \"/datadrive/Datasets/lowlands-data/ACL2014/crowdsourced_POS/data/foster-twitter.test\"\n",
    "            output_dir = os.path.join(OUTPUT_DIRECTORY, task_name, key)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            output_file = os.path.join(output_dir, \"{}.conll\".format(split_prefix))\n",
    "            stats = process_file(input_files, output_file, token_idx, label_idx, parse_label)\n",
    "            stats[\"labels\"] = list(sorted(stats[\"labels_vocab\"].keys()))\n",
    "            if split_boundary:\n",
    "                boundaries, labels = zip(*[split_label(label) for label in stats[\"labels_vocab\"].keys()])\n",
    "                stats[\"boundaries\"] = list(set(boundaries))\n",
    "                stats[\"labels\"] = list(set([l for l in labels if l]))\n",
    "                stats[\"labels_unique\"] = len(stats[\"labels\"])\n",
    "            stats[\"data_key\"] = key\n",
    "            stats[\"split_prefix\"] = split_prefix\n",
    "            stats_data.append(stats)\n",
    "            print(\"{:15s}\\t{:5s}\\t{}\".format(key, split_prefix, output_file))\n",
    "    return stats_data\n",
    "\n",
    "def show_stats(stats_data, data_order=None):\n",
    "    df = pd.DataFrame(stats_data).drop([\"tokens_vocab\", \"labels_vocab\"], 1).set_index([\"data_key\", \"split_prefix\"])\n",
    "    with pd.option_context(\"display.max_colwidth\", -1):\n",
    "        display(df)\n",
    "        print(df.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_FILES={\n",
    "    \"Owoputi\": {\n",
    "        \"train\": [\n",
    "            \"/datadrive/Datasets/Twitter/TweeboParser/ark-tweet-nlp-0.3.2/data/twpos-data-v0.3/oct27.splits/oct27.train\",\n",
    "            \"/datadrive/Datasets/Twitter/TweeboParser/ark-tweet-nlp-0.3.2/data/twpos-data-v0.3/daily547.conll\"\n",
    "        ],\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/TweeboParser/ark-tweet-nlp-0.3.2/data/twpos-data-v0.3/oct27.splits/oct27.dev\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/TweeboParser/ark-tweet-nlp-0.3.2/data/twpos-data-v0.3/oct27.splits/oct27.test\",\n",
    "    },\n",
    "    \"Foster\": {\n",
    "        \"test\": \"/datadrive/Datasets/lowlands-data/ACL2014/crowdsourced_POS/data/foster-twitter.test\",\n",
    "    },\n",
    "    \"TwitIE\": {\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/twitter-pos-bootstrap/data/foster_dev.conll\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/twitter-pos-bootstrap/data/foster_eval.conll\"\n",
    "    },\n",
    "    \"Ritter\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/pos.cleaned.train.txt\",\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/pos.cleaned.dev.txt\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/pos.cleaned.test.txt\",\n",
    "    },\n",
    "    \"lowlands\": {\n",
    "        \"test\": [\n",
    "            \"/datadrive/Datasets/lowlands-data/ACL2014/crowdsourced_POS/data/lowlands.test\",\n",
    "            \"/datadrive/Datasets/lowlands-data/ACL2014/crowdsourced_POS/data/ritter.test\",\n",
    "            \"/datadrive/Datasets/lowlands-data/ACL2014/crowdsourced_POS/data/gimpel.GOLD\"\n",
    "        ]\n",
    "    },\n",
    "    \"Tweetbankv2\": {\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/Tweebank/pos/en-ud-tweet-dev.txt\",\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/Tweebank/pos/en-ud-tweet-train.txt\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/Tweebank/pos/en-ud-tweet-test.txt\",\n",
    "    }\n",
    "}\n",
    "\n",
    "DIMSUM_FILES = {\n",
    "    \"DiMSUM2016\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/dimsum-data/conll/dimsum16.train\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/dimsum-data/conll/dimsum16.test\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Owoputi        \ttrain\t../data/processed/POS\\Owoputi\\train.conll\n",
      "Owoputi        \tdev  \t../data/processed/POS\\Owoputi\\dev.conll\n",
      "Owoputi        \ttest \t../data/processed/POS\\Owoputi\\test.conll\n",
      "Foster         \ttest \t../data/processed/POS\\Foster\\test.conll\n",
      "TwitIE         \tdev  \t../data/processed/POS\\TwitIE\\dev.conll\n",
      "TwitIE         \ttest \t../data/processed/POS\\TwitIE\\test.conll\n",
      "Ritter         \ttrain\t../data/processed/POS\\Ritter\\train.conll\n",
      "Ritter         \tdev  \t../data/processed/POS\\Ritter\\dev.conll\n",
      "Ritter         \ttest \t../data/processed/POS\\Ritter\\test.conll\n",
      "lowlands       \ttest \t../data/processed/POS\\lowlands\\test.conll\n",
      "Tweetbankv2    \tdev  \t../data/processed/POS\\Tweetbankv2\\dev.conll\n",
      "Tweetbankv2    \ttrain\t../data/processed/POS\\Tweetbankv2\\train.conll\n",
      "Tweetbankv2    \ttest \t../data/processed/POS\\Tweetbankv2\\test.conll\n",
      "DiMSUM2016     \ttrain\t../data/processed/POS\\DiMSUM2016\\train.conll\n",
      "DiMSUM2016     \ttest \t../data/processed/POS\\DiMSUM2016\\test.conll\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_unique</th>\n",
       "      <th>sequences</th>\n",
       "      <th>tokens_unique</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_key</th>\n",
       "      <th>split_prefix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Owoputi</th>\n",
       "      <th>train</th>\n",
       "      <td>[!, #, $, &amp;, ,, @, A, D, E, G, L, M, N, O, P, R, S, T, U, V, X, Y, Z, ^, ~]</td>\n",
       "      <td>25</td>\n",
       "      <td>1547</td>\n",
       "      <td>6572</td>\n",
       "      <td>22326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[!, #, $, &amp;, ,, @, A, D, E, G, L, N, O, P, R, S, T, U, V, X, Z, ^, ~]</td>\n",
       "      <td>23</td>\n",
       "      <td>327</td>\n",
       "      <td>2036</td>\n",
       "      <td>4823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[!, #, $, &amp;, ,, @, A, D, E, G, L, N, O, P, R, S, T, U, V, X, Z, ^, ~]</td>\n",
       "      <td>23</td>\n",
       "      <td>500</td>\n",
       "      <td>2754</td>\n",
       "      <td>7152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Foster</th>\n",
       "      <th>test</th>\n",
       "      <td>[ADJ, ADP, ADV, CCONJ, DET, NOUN, NUM, PART, PRON, PUNCT, VERB, X]</td>\n",
       "      <td>12</td>\n",
       "      <td>250</td>\n",
       "      <td>1068</td>\n",
       "      <td>2841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TwitIE</th>\n",
       "      <th>dev</th>\n",
       "      <td>['', (, ), ,, :, CC, CD, DT, FW, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]</td>\n",
       "      <td>43</td>\n",
       "      <td>269</td>\n",
       "      <td>1229</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>['', (, ), ,, :, CC, CD, DT, EX, FW, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]</td>\n",
       "      <td>44</td>\n",
       "      <td>250</td>\n",
       "      <td>1182</td>\n",
       "      <td>2841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ritter</th>\n",
       "      <th>train</th>\n",
       "      <td>['', (, ), ,, :, CC, CD, DT, EX, FW, HT, IN, JJ, JJR, JJS, LS, MD, NN, NNP, NNPS, NNS, O, POS, PRP, PRP$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]</td>\n",
       "      <td>45</td>\n",
       "      <td>632</td>\n",
       "      <td>3539</td>\n",
       "      <td>12196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>['', (, ), ,, :, CC, CD, DT, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNS, POS, PRP, PRP$, PUNCT, RB, RBR, RP, RT, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]</td>\n",
       "      <td>38</td>\n",
       "      <td>71</td>\n",
       "      <td>695</td>\n",
       "      <td>1362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>['', (, ), ,, :, CC, CD, DT, EX, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP$, PUNCT, RB, RBR, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WRB]</td>\n",
       "      <td>41</td>\n",
       "      <td>84</td>\n",
       "      <td>735</td>\n",
       "      <td>1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lowlands</th>\n",
       "      <th>test</th>\n",
       "      <td>[ADJ, ADP, ADV, CCONJ, DET, NOUN, NUM, PART, PRON, PUNCT, VERB, X]</td>\n",
       "      <td>12</td>\n",
       "      <td>1318</td>\n",
       "      <td>4805</td>\n",
       "      <td>19794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Tweetbankv2</th>\n",
       "      <th>dev</th>\n",
       "      <td>[ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]</td>\n",
       "      <td>17</td>\n",
       "      <td>710</td>\n",
       "      <td>3271</td>\n",
       "      <td>11759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>[ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]</td>\n",
       "      <td>17</td>\n",
       "      <td>1639</td>\n",
       "      <td>5632</td>\n",
       "      <td>24753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]</td>\n",
       "      <td>17</td>\n",
       "      <td>1201</td>\n",
       "      <td>4699</td>\n",
       "      <td>19095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DiMSUM2016</th>\n",
       "      <th>train</th>\n",
       "      <td>[ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]</td>\n",
       "      <td>17</td>\n",
       "      <td>4799</td>\n",
       "      <td>9113</td>\n",
       "      <td>73826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]</td>\n",
       "      <td>17</td>\n",
       "      <td>1000</td>\n",
       "      <td>4010</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                            labels  \\\n",
       "data_key    split_prefix                                                                                                                                                                                                             \n",
       "Owoputi     train         [!, #, $, &, ,, @, A, D, E, G, L, M, N, O, P, R, S, T, U, V, X, Y, Z, ^, ~]                                                                                                                                \n",
       "            dev           [!, #, $, &, ,, @, A, D, E, G, L, N, O, P, R, S, T, U, V, X, Z, ^, ~]                                                                                                                                      \n",
       "            test          [!, #, $, &, ,, @, A, D, E, G, L, N, O, P, R, S, T, U, V, X, Z, ^, ~]                                                                                                                                      \n",
       "Foster      test          [ADJ, ADP, ADV, CCONJ, DET, NOUN, NUM, PART, PRON, PUNCT, VERB, X]                                                                                                                                         \n",
       "TwitIE      dev           ['', (, ), ,, :, CC, CD, DT, FW, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]         \n",
       "            test          ['', (, ), ,, :, CC, CD, DT, EX, FW, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]     \n",
       "Ritter      train         ['', (, ), ,, :, CC, CD, DT, EX, FW, HT, IN, JJ, JJR, JJS, LS, MD, NN, NNP, NNPS, NNS, O, POS, PRP, PRP$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]   \n",
       "            dev           ['', (, ), ,, :, CC, CD, DT, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNS, POS, PRP, PRP$, PUNCT, RB, RBR, RP, RT, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB]                                  \n",
       "            test          ['', (, ), ,, :, CC, CD, DT, EX, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP$, PUNCT, RB, RBR, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WRB]                  \n",
       "lowlands    test          [ADJ, ADP, ADV, CCONJ, DET, NOUN, NUM, PART, PRON, PUNCT, VERB, X]                                                                                                                                         \n",
       "Tweetbankv2 dev           [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]                                                                                                           \n",
       "            train         [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]                                                                                                           \n",
       "            test          [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]                                                                                                           \n",
       "DiMSUM2016  train         [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]                                                                                                           \n",
       "            test          [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X]                                                                                                           \n",
       "\n",
       "                          labels_unique  sequences  tokens_unique  \\\n",
       "data_key    split_prefix                                            \n",
       "Owoputi     train         25             1547       6572            \n",
       "            dev           23             327        2036            \n",
       "            test          23             500        2754            \n",
       "Foster      test          12             250        1068            \n",
       "TwitIE      dev           43             269        1229            \n",
       "            test          44             250        1182            \n",
       "Ritter      train         45             632        3539            \n",
       "            dev           38             71         695             \n",
       "            test          41             84         735             \n",
       "lowlands    test          12             1318       4805            \n",
       "Tweetbankv2 dev           17             710        3271            \n",
       "            train         17             1639       5632            \n",
       "            test          17             1201       4699            \n",
       "DiMSUM2016  train         17             4799       9113            \n",
       "            test          17             1000       4010            \n",
       "\n",
       "                          total_tokens  \n",
       "data_key    split_prefix                \n",
       "Owoputi     train         22326         \n",
       "            dev           4823          \n",
       "            test          7152          \n",
       "Foster      test          2841          \n",
       "TwitIE      dev           2998          \n",
       "            test          2841          \n",
       "Ritter      train         12196         \n",
       "            dev           1362          \n",
       "            test          1627          \n",
       "lowlands    test          19794         \n",
       "Tweetbankv2 dev           11759         \n",
       "            train         24753         \n",
       "            test          19095         \n",
       "DiMSUM2016  train         73826         \n",
       "            test          16500         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllrrrr}\n",
      "\\toprule\n",
      "           &      &                                                                                                                                                                                                    labels &  labels\\_unique &  sequences &  tokens\\_unique &  total\\_tokens \\\\\n",
      "data\\_key & split\\_prefix &                                                                                                                                                                                                           &                &            &                &               \\\\\n",
      "\\midrule\n",
      "Owoputi & train &  [!, \\#, \\$, \\&, ,, @, A, D, E, G, L, M, N, O, P, R, S, T, U, V, X, Y, Z, \\textasciicircum , \\textasciitilde ] &  25 &  1547 &  6572 &  22326 \\\\\n",
      "           & dev &  [!, \\#, \\$, \\&, ,, @, A, D, E, G, L, N, O, P, R, S, T, U, V, X, Z, \\textasciicircum , \\textasciitilde ] &  23 &  327 &  2036 &  4823 \\\\\n",
      "           & test &  [!, \\#, \\$, \\&, ,, @, A, D, E, G, L, N, O, P, R, S, T, U, V, X, Z, \\textasciicircum , \\textasciitilde ] &  23 &  500 &  2754 &  7152 \\\\\n",
      "Foster & test &  [ADJ, ADP, ADV, CCONJ, DET, NOUN, NUM, PART, PRON, PUNCT, VERB, X] &  12 &  250 &  1068 &  2841 \\\\\n",
      "TwitIE & dev &  ['', (, ), ,, :, CC, CD, DT, FW, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP\\$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB] &  43 &  269 &  1229 &  2998 \\\\\n",
      "           & test &  ['', (, ), ,, :, CC, CD, DT, EX, FW, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP\\$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB] &  44 &  250 &  1182 &  2841 \\\\\n",
      "Ritter & train &  ['', (, ), ,, :, CC, CD, DT, EX, FW, HT, IN, JJ, JJR, JJS, LS, MD, NN, NNP, NNPS, NNS, O, POS, PRP, PRP\\$, PUNCT, RB, RBR, RBS, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB] &  45 &  632 &  3539 &  12196 \\\\\n",
      "           & dev &  ['', (, ), ,, :, CC, CD, DT, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNS, POS, PRP, PRP\\$, PUNCT, RB, RBR, RP, RT, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WP, WRB] &  38 &  71 &  695 &  1362 \\\\\n",
      "           & test &  ['', (, ), ,, :, CC, CD, DT, EX, HT, IN, JJ, JJR, JJS, MD, NN, NNP, NNPS, NNS, PDT, POS, PRP, PRP\\$, PUNCT, RB, RBR, RP, RT, SYM, TO, UH, URL, USR, VB, VBD, VBG, VBN, VBP, VBZ, WDT, WRB] &  41 &  84 &  735 &  1627 \\\\\n",
      "lowlands & test &  [ADJ, ADP, ADV, CCONJ, DET, NOUN, NUM, PART, PRON, PUNCT, VERB, X] &  12 &  1318 &  4805 &  19794 \\\\\n",
      "Tweetbankv2 & dev &  [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X] &  17 &  710 &  3271 &  11759 \\\\\n",
      "           & train &  [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X] &  17 &  1639 &  5632 &  24753 \\\\\n",
      "           & test &  [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X] &  17 &  1201 &  4699 &  19095 \\\\\n",
      "DiMSUM2016 & train &  [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X] &  17 &  4799 &  9113 &  73826 \\\\\n",
      "           & test &  [ADJ, ADP, ADV, AUX, CCONJ, DET, INTJ, NOUN, NUM, PART, PRON, PROPN, PUNCT, SCONJ, SYM, VERB, X] &  17 &  1000 &  4010 &  16500 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_data = gather_data(POS_FILES, \"POS\", split_boundary=False, parse_label=clean_pos_label);\n",
    "stats_data = gather_data(DIMSUM_FILES, \"POS\", split_boundary=False, token_idx=1, label_idx=3, parse_label=clean_pos_label, stats_data=stats_data);\n",
    "show_stats(stats_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNKING_FILES = {\n",
    "    \"Ritter\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/chunk.train.conll\",\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/chunk.dev.conll\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/chunk.test.conll\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ritter         \ttrain\t../data/processed/CHUNKING\\Ritter\\train.conll\n",
      "Ritter         \tdev  \t../data/processed/CHUNKING\\Ritter\\dev.conll\n",
      "Ritter         \ttest \t../data/processed/CHUNKING\\Ritter\\test.conll\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>boundaries</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_unique</th>\n",
       "      <th>sequences</th>\n",
       "      <th>tokens_unique</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_key</th>\n",
       "      <th>split_prefix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ritter</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP, CONJP]</td>\n",
       "      <td>9</td>\n",
       "      <td>551</td>\n",
       "      <td>3158</td>\n",
       "      <td>10584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP]</td>\n",
       "      <td>8</td>\n",
       "      <td>118</td>\n",
       "      <td>994</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP]</td>\n",
       "      <td>8</td>\n",
       "      <td>119</td>\n",
       "      <td>988</td>\n",
       "      <td>2310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      boundaries  \\\n",
       "data_key split_prefix              \n",
       "Ritter   train         [I, B, O]   \n",
       "         dev           [I, B, O]   \n",
       "         test          [I, B, O]   \n",
       "\n",
       "                                                                 labels  \\\n",
       "data_key split_prefix                                                     \n",
       "Ritter   train         [ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP, CONJP]   \n",
       "         dev           [ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP]          \n",
       "         test          [ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP]          \n",
       "\n",
       "                       labels_unique  sequences  tokens_unique  total_tokens  \n",
       "data_key split_prefix                                                         \n",
       "Ritter   train         9              551        3158           10584         \n",
       "         dev           8              118        994            2317          \n",
       "         test          8              119        988            2310          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllrrrr}\n",
      "\\toprule\n",
      "       &      & boundaries &                                            labels &  labels\\_unique &  sequences &  tokens\\_unique &  total\\_tokens \\\\\n",
      "data\\_key & split\\_prefix &            &                                                   &                &            &                &               \\\\\n",
      "\\midrule\n",
      "Ritter & train &  [I, B, O] &  [ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP, CONJP] &  9 &  551 &  3158 &  10584 \\\\\n",
      "       & dev &  [I, B, O] &  [ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP] &  8 &  118 &  994 &  2317 \\\\\n",
      "       & test &  [I, B, O] &  [ADJP, PP, INTJ, ADVP, PRT, NP, SBAR, VP] &  8 &  119 &  988 &  2310 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_data = gather_data(CHUNKING_FILES, \"CHUNKING\", split_boundary=True);\n",
    "show_stats(stats_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NER_FILES={\n",
    "    \"Finin\": {\n",
    "        \"train\": \"/datadrive/Datasets/lowlands-data/LREC2014/twitter_ner/data/finin.train.tsv\",\n",
    "        \"test\": [\n",
    "            \"/datadrive/Datasets/lowlands-data/LREC2014/twitter_ner/data/finin.test.tsv.utf8\",\n",
    "            \"/datadrive/Datasets/lowlands-data/LREC2014/twitter_ner/data/ritter.test.tsv\"\n",
    "        ],\n",
    "    },\n",
    "    \"Hege\": {\n",
    "        \"test\": \"/datadrive/Datasets/lowlands-data/LREC2014/twitter_ner/data/hege.test.tsv\",\n",
    "    },\n",
    "    \"Ritter\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/ner.train.txt\",\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/ner.dev.txt\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/RitterNER/twitter_processed/ner.test.txt\",\n",
    "    },\n",
    "    \"YODIE\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/YODIE/data/training.conll\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/YODIE/data/testing.conll\"\n",
    "    },\n",
    "    \"WNUT2016\": {\n",
    "        \"train\": \"/datadrive/Codes/multi-task-nlp-keras/data/WNUT_NER/train.tsv\",\n",
    "        \"test\": \"/datadrive/Codes/multi-task-nlp-keras/data/WNUT_NER/test.tsv\",\n",
    "        \"dev\": \"/datadrive/Codes/multi-task-nlp-keras/data/WNUT_NER/dev.tsv\",\n",
    "    },\n",
    "    \"WNUT2017\": {\n",
    "        \"train\": \"/datadrive/Codes/multi-task-nlp-keras/data/WNUT_2017/wnut17train.conll\",\n",
    "        \"dev\": \"/datadrive/Codes/multi-task-nlp-keras/data/WNUT_2017/emerging.dev.conll\",\n",
    "        \"test\": \"/datadrive/Codes/multi-task-nlp-keras/data/WNUT_2017/emerging.test.annotated\",\n",
    "    },\n",
    "    \"MSM2013\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/MSM2013/data/msm2013-ce_challenge_gs/TweetsTrainingSetCH.tsv.conll\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/MSM2013/data/msm2013-ce_challenge_gs/goldStandard.tsv.conll\",\n",
    "    },\n",
    "    \"NEEL2016\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/microposts-NEEL/processed/2016/microposts2016-neel-training_neel.gs.conll\",\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/microposts-NEEL/processed/2016/microposts2016-neel-dev_neel.gs.conll\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/microposts-NEEL/processed/2016/microposts2016-neel-test_neel.gs.conll\",\n",
    "    },\n",
    "    \"BROAD\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/broad_twitter_corpus/data_splits/train.conll\",\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/broad_twitter_corpus/data_splits/dev.conll\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/broad_twitter_corpus/data_splits/test.conll\",\n",
    "        \n",
    "    },\n",
    "    \"MultiModal\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/NERmultimodal/data/train.conll\",\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/NERmultimodal/data/dev.conll\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/NERmultimodal/data/test.conll\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finin          \ttrain\t../data/processed/NER\\Finin\\train.conll\n",
      "Finin          \ttest \t../data/processed/NER\\Finin\\test.conll\n",
      "Hege           \ttest \t../data/processed/NER\\Hege\\test.conll\n",
      "Ritter         \ttrain\t../data/processed/NER\\Ritter\\train.conll\n",
      "Ritter         \tdev  \t../data/processed/NER\\Ritter\\dev.conll\n",
      "Ritter         \ttest \t../data/processed/NER\\Ritter\\test.conll\n",
      "YODIE          \ttrain\t../data/processed/NER\\YODIE\\train.conll\n",
      "YODIE          \ttest \t../data/processed/NER\\YODIE\\test.conll\n",
      "WNUT2016       \ttrain\t../data/processed/NER\\WNUT2016\\train.conll\n",
      "WNUT2016       \ttest \t../data/processed/NER\\WNUT2016\\test.conll\n",
      "WNUT2016       \tdev  \t../data/processed/NER\\WNUT2016\\dev.conll\n",
      "WNUT2017       \ttrain\t../data/processed/NER\\WNUT2017\\train.conll\n",
      "WNUT2017       \tdev  \t../data/processed/NER\\WNUT2017\\dev.conll\n",
      "WNUT2017       \ttest \t../data/processed/NER\\WNUT2017\\test.conll\n",
      "MSM2013        \ttrain\t../data/processed/NER\\MSM2013\\train.conll\n",
      "MSM2013        \ttest \t../data/processed/NER\\MSM2013\\test.conll\n",
      "NEEL2016       \ttrain\t../data/processed/NER\\NEEL2016\\train.conll\n",
      "NEEL2016       \tdev  \t../data/processed/NER\\NEEL2016\\dev.conll\n",
      "NEEL2016       \ttest \t../data/processed/NER\\NEEL2016\\test.conll\n",
      "BROAD          \ttrain\t../data/processed/NER\\BROAD\\train.conll\n",
      "BROAD          \tdev  \t../data/processed/NER\\BROAD\\dev.conll\n",
      "BROAD          \ttest \t../data/processed/NER\\BROAD\\test.conll\n",
      "MultiModal     \ttrain\t../data/processed/NER\\MultiModal\\train.conll\n",
      "MultiModal     \tdev  \t../data/processed/NER\\MultiModal\\dev.conll\n",
      "MultiModal     \ttest \t../data/processed/NER\\MultiModal\\test.conll\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>boundaries</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_unique</th>\n",
       "      <th>sequences</th>\n",
       "      <th>tokens_unique</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_key</th>\n",
       "      <th>split_prefix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Finin</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG]</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>19663</td>\n",
       "      <td>172188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG]</td>\n",
       "      <td>3</td>\n",
       "      <td>5369</td>\n",
       "      <td>13027</td>\n",
       "      <td>97525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hege</th>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG]</td>\n",
       "      <td>3</td>\n",
       "      <td>1545</td>\n",
       "      <td>4552</td>\n",
       "      <td>20664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ritter</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]</td>\n",
       "      <td>10</td>\n",
       "      <td>1900</td>\n",
       "      <td>7695</td>\n",
       "      <td>36936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]</td>\n",
       "      <td>10</td>\n",
       "      <td>240</td>\n",
       "      <td>1731</td>\n",
       "      <td>4612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]</td>\n",
       "      <td>10</td>\n",
       "      <td>254</td>\n",
       "      <td>1776</td>\n",
       "      <td>4921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">YODIE</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, PERSON, LOCATION, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, UNK, TVSHOW, PRODUCT, SPORTSTEAM, ORGANIZATION]</td>\n",
       "      <td>13</td>\n",
       "      <td>396</td>\n",
       "      <td>2554</td>\n",
       "      <td>7905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, FACILITY, LOCATION, PERSON, MOVIE, MUSICARTIST, GEO-LOC, UNK, TVSHOW, PRODUCT, SPORTSTEAM, ORGANIZATION]</td>\n",
       "      <td>13</td>\n",
       "      <td>397</td>\n",
       "      <td>2578</td>\n",
       "      <td>8032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">WNUT2016</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]</td>\n",
       "      <td>10</td>\n",
       "      <td>2394</td>\n",
       "      <td>9068</td>\n",
       "      <td>46469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]</td>\n",
       "      <td>10</td>\n",
       "      <td>3850</td>\n",
       "      <td>16012</td>\n",
       "      <td>61908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>5563</td>\n",
       "      <td>16261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">WNUT2017</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK]</td>\n",
       "      <td>6</td>\n",
       "      <td>3394</td>\n",
       "      <td>12840</td>\n",
       "      <td>62730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK]</td>\n",
       "      <td>6</td>\n",
       "      <td>1009</td>\n",
       "      <td>3538</td>\n",
       "      <td>15733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK]</td>\n",
       "      <td>6</td>\n",
       "      <td>1287</td>\n",
       "      <td>5759</td>\n",
       "      <td>23394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">MSM2013</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, MISC, PER, ORG]</td>\n",
       "      <td>4</td>\n",
       "      <td>2815</td>\n",
       "      <td>8514</td>\n",
       "      <td>51521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG, MISC]</td>\n",
       "      <td>4</td>\n",
       "      <td>1450</td>\n",
       "      <td>5701</td>\n",
       "      <td>29089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">NEEL2016</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[PERSON, THING, LOCATION, EVENT, PRODUCT, ORGANIZATION, CHARACTER]</td>\n",
       "      <td>7</td>\n",
       "      <td>2588</td>\n",
       "      <td>9731</td>\n",
       "      <td>51669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[PERSON, LOCATION, THING, EVENT, PRODUCT, ORGANIZATION, CHARACTER]</td>\n",
       "      <td>7</td>\n",
       "      <td>88</td>\n",
       "      <td>762</td>\n",
       "      <td>1647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[PERSON, THING, LOCATION, EVENT, PRODUCT, ORGANIZATION, CHARACTER]</td>\n",
       "      <td>7</td>\n",
       "      <td>2663</td>\n",
       "      <td>9894</td>\n",
       "      <td>47488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">BROAD</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG]</td>\n",
       "      <td>3</td>\n",
       "      <td>5605</td>\n",
       "      <td>19523</td>\n",
       "      <td>90060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG]</td>\n",
       "      <td>3</td>\n",
       "      <td>933</td>\n",
       "      <td>5312</td>\n",
       "      <td>15169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG]</td>\n",
       "      <td>3</td>\n",
       "      <td>2802</td>\n",
       "      <td>11772</td>\n",
       "      <td>45159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">MultiModal</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG, MISC]</td>\n",
       "      <td>4</td>\n",
       "      <td>4000</td>\n",
       "      <td>20221</td>\n",
       "      <td>64439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, MISC, PER, ORG]</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>6832</td>\n",
       "      <td>16178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[LOC, PER, ORG, MISC]</td>\n",
       "      <td>4</td>\n",
       "      <td>3257</td>\n",
       "      <td>17381</td>\n",
       "      <td>52822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        boundaries  \\\n",
       "data_key   split_prefix              \n",
       "Finin      train         [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "Hege       test          [I, B, O]   \n",
       "Ritter     train         [I, B, O]   \n",
       "           dev           [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "YODIE      train         [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "WNUT2016   train         [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "           dev           [I, B, O]   \n",
       "WNUT2017   train         [I, B, O]   \n",
       "           dev           [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "MSM2013    train         [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "NEEL2016   train         [I, B, O]   \n",
       "           dev           [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "BROAD      train         [I, B, O]   \n",
       "           dev           [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "MultiModal train         [I, B, O]   \n",
       "           dev           [I, B, O]   \n",
       "           test          [I, B, O]   \n",
       "\n",
       "                                                                                                                                            labels  \\\n",
       "data_key   split_prefix                                                                                                                              \n",
       "Finin      train         [LOC, PER, ORG]                                                                                                             \n",
       "           test          [LOC, PER, ORG]                                                                                                             \n",
       "Hege       test          [LOC, PER, ORG]                                                                                                             \n",
       "Ritter     train         [COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]                                \n",
       "           dev           [COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]                                \n",
       "           test          [COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]                                \n",
       "YODIE      train         [COMPANY, OTHER, PERSON, LOCATION, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, UNK, TVSHOW, PRODUCT, SPORTSTEAM, ORGANIZATION]   \n",
       "           test          [COMPANY, OTHER, FACILITY, LOCATION, PERSON, MOVIE, MUSICARTIST, GEO-LOC, UNK, TVSHOW, PRODUCT, SPORTSTEAM, ORGANIZATION]   \n",
       "WNUT2016   train         [COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]                                \n",
       "           test          [COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]                                \n",
       "           dev           [COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM]                                \n",
       "WNUT2017   train         [GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK]                                                              \n",
       "           dev           [GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK]                                                              \n",
       "           test          [GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK]                                                              \n",
       "MSM2013    train         [LOC, MISC, PER, ORG]                                                                                                       \n",
       "           test          [LOC, PER, ORG, MISC]                                                                                                       \n",
       "NEEL2016   train         [PERSON, THING, LOCATION, EVENT, PRODUCT, ORGANIZATION, CHARACTER]                                                          \n",
       "           dev           [PERSON, LOCATION, THING, EVENT, PRODUCT, ORGANIZATION, CHARACTER]                                                          \n",
       "           test          [PERSON, THING, LOCATION, EVENT, PRODUCT, ORGANIZATION, CHARACTER]                                                          \n",
       "BROAD      train         [LOC, PER, ORG]                                                                                                             \n",
       "           dev           [LOC, PER, ORG]                                                                                                             \n",
       "           test          [LOC, PER, ORG]                                                                                                             \n",
       "MultiModal train         [LOC, PER, ORG, MISC]                                                                                                       \n",
       "           dev           [LOC, MISC, PER, ORG]                                                                                                       \n",
       "           test          [LOC, PER, ORG, MISC]                                                                                                       \n",
       "\n",
       "                         labels_unique  sequences  tokens_unique  total_tokens  \n",
       "data_key   split_prefix                                                         \n",
       "Finin      train         3              10000      19663          172188        \n",
       "           test          3              5369       13027          97525         \n",
       "Hege       test          3              1545       4552           20664         \n",
       "Ritter     train         10             1900       7695           36936         \n",
       "           dev           10             240        1731           4612          \n",
       "           test          10             254        1776           4921          \n",
       "YODIE      train         13             396        2554           7905          \n",
       "           test          13             397        2578           8032          \n",
       "WNUT2016   train         10             2394       9068           46469         \n",
       "           test          10             3850       16012          61908         \n",
       "           dev           10             1000       5563           16261         \n",
       "WNUT2017   train         6              3394       12840          62730         \n",
       "           dev           6              1009       3538           15733         \n",
       "           test          6              1287       5759           23394         \n",
       "MSM2013    train         4              2815       8514           51521         \n",
       "           test          4              1450       5701           29089         \n",
       "NEEL2016   train         7              2588       9731           51669         \n",
       "           dev           7              88         762            1647          \n",
       "           test          7              2663       9894           47488         \n",
       "BROAD      train         3              5605       19523          90060         \n",
       "           dev           3              933        5312           15169         \n",
       "           test          3              2802       11772          45159         \n",
       "MultiModal train         4              4000       20221          64439         \n",
       "           dev           4              1000       6832           16178         \n",
       "           test          4              3257       17381          52822         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllrrrr}\n",
      "\\toprule\n",
      "           &      & boundaries &                                                                                                                     labels &  labels\\_unique &  sequences &  tokens\\_unique &  total\\_tokens \\\\\n",
      "data\\_key & split\\_prefix &            &                                                                                                                            &                &            &                &               \\\\\n",
      "\\midrule\n",
      "Finin & train &  [I, B, O] &  [LOC, PER, ORG] &  3 &  10000 &  19663 &  172188 \\\\\n",
      "           & test &  [I, B, O] &  [LOC, PER, ORG] &  3 &  5369 &  13027 &  97525 \\\\\n",
      "Hege & test &  [I, B, O] &  [LOC, PER, ORG] &  3 &  1545 &  4552 &  20664 \\\\\n",
      "Ritter & train &  [I, B, O] &  [COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM] &  10 &  1900 &  7695 &  36936 \\\\\n",
      "           & dev &  [I, B, O] &  [COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM] &  10 &  240 &  1731 &  4612 \\\\\n",
      "           & test &  [I, B, O] &  [COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM] &  10 &  254 &  1776 &  4921 \\\\\n",
      "YODIE & train &  [I, B, O] &  [COMPANY, OTHER, PERSON, LOCATION, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, UNK, TVSHOW, PRODUCT, SPORTSTEAM, ORGANIZATION] &  13 &  396 &  2554 &  7905 \\\\\n",
      "           & test &  [I, B, O] &  [COMPANY, OTHER, FACILITY, LOCATION, PERSON, MOVIE, MUSICARTIST, GEO-LOC, UNK, TVSHOW, PRODUCT, SPORTSTEAM, ORGANIZATION] &  13 &  397 &  2578 &  8032 \\\\\n",
      "WNUT2016 & train &  [I, B, O] &  [COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM] &  10 &  2394 &  9068 &  46469 \\\\\n",
      "           & test &  [I, B, O] &  [COMPANY, OTHER, PERSON, FACILITY, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM] &  10 &  3850 &  16012 &  61908 \\\\\n",
      "           & dev &  [I, B, O] &  [COMPANY, OTHER, FACILITY, PERSON, MOVIE, MUSICARTIST, GEO-LOC, TVSHOW, PRODUCT, SPORTSTEAM] &  10 &  1000 &  5563 &  16261 \\\\\n",
      "WNUT2017 & train &  [I, B, O] &  [GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK] &  6 &  3394 &  12840 &  62730 \\\\\n",
      "           & dev &  [I, B, O] &  [GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK] &  6 &  1009 &  3538 &  15733 \\\\\n",
      "           & test &  [I, B, O] &  [GROUP, CORPORATION, PERSON, LOCATION, PRODUCT, CREATIVE-WORK] &  6 &  1287 &  5759 &  23394 \\\\\n",
      "MSM2013 & train &  [I, B, O] &  [LOC, MISC, PER, ORG] &  4 &  2815 &  8514 &  51521 \\\\\n",
      "           & test &  [I, B, O] &  [LOC, PER, ORG, MISC] &  4 &  1450 &  5701 &  29089 \\\\\n",
      "NEEL2016 & train &  [I, B, O] &  [PERSON, THING, LOCATION, EVENT, PRODUCT, ORGANIZATION, CHARACTER] &  7 &  2588 &  9731 &  51669 \\\\\n",
      "           & dev &  [I, B, O] &  [PERSON, LOCATION, THING, EVENT, PRODUCT, ORGANIZATION, CHARACTER] &  7 &  88 &  762 &  1647 \\\\\n",
      "           & test &  [I, B, O] &  [PERSON, THING, LOCATION, EVENT, PRODUCT, ORGANIZATION, CHARACTER] &  7 &  2663 &  9894 &  47488 \\\\\n",
      "BROAD & train &  [I, B, O] &  [LOC, PER, ORG] &  3 &  5605 &  19523 &  90060 \\\\\n",
      "           & dev &  [I, B, O] &  [LOC, PER, ORG] &  3 &  933 &  5312 &  15169 \\\\\n",
      "           & test &  [I, B, O] &  [LOC, PER, ORG] &  3 &  2802 &  11772 &  45159 \\\\\n",
      "MultiModal & train &  [I, B, O] &  [LOC, PER, ORG, MISC] &  4 &  4000 &  20221 &  64439 \\\\\n",
      "           & dev &  [I, B, O] &  [LOC, MISC, PER, ORG] &  4 &  1000 &  6832 &  16178 \\\\\n",
      "           & test &  [I, B, O] &  [LOC, PER, ORG, MISC] &  4 &  3257 &  17381 &  52822 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_data = gather_data(NER_FILES, \"NER\", split_boundary=True, parse_label=clean_ner_label);\n",
    "show_stats(stats_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supersense tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPERSENSE_TAGGING_FILES={\n",
    "    \"Ritter\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/supersense-data-twitter/ritter-train.tsv\",\n",
    "        \"dev\": \"/datadrive/Datasets/Twitter/supersense-data-twitter/ritter-dev.tsv\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/supersense-data-twitter/ritter-eval.tsv\"\n",
    "    },\n",
    "    \"Johannsen2014\": {\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/supersense-data-twitter/in-house-eval.tsv\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# This dataset has some tagging issues as the super sense tags are assigned to multi-word units which are not contigous\n",
    "DIMSUM_FILES = {\n",
    "    \"DiMSUM2016\": {\n",
    "        \"train\": \"/datadrive/Datasets/Twitter/dimsum-data/conll/dimsum16.train\",\n",
    "        \"test\": \"/datadrive/Datasets/Twitter/dimsum-data/conll/dimsum16.test\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ritter         \ttrain\t../data/processed/SUPERSENSE\\Ritter\\train.conll\n",
      "Ritter         \tdev  \t../data/processed/SUPERSENSE\\Ritter\\dev.conll\n",
      "Ritter         \ttest \t../data/processed/SUPERSENSE\\Ritter\\test.conll\n",
      "Johannsen2014  \ttest \t../data/processed/SUPERSENSE\\Johannsen2014\\test.conll\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>boundaries</th>\n",
       "      <th>labels</th>\n",
       "      <th>labels_unique</th>\n",
       "      <th>sequences</th>\n",
       "      <th>tokens_unique</th>\n",
       "      <th>total_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_key</th>\n",
       "      <th>split_prefix</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Ritter</th>\n",
       "      <th>train</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.TOPS, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.POSSESSION, VERB.COMPETITION, NOUN.POSSESSION, NOUN.FEELING, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.WEATHER, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, NOUN.PLANT, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE]</td>\n",
       "      <td>40</td>\n",
       "      <td>551</td>\n",
       "      <td>3174</td>\n",
       "      <td>10652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dev</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.COMPETITION, VERB.POSSESSION, NOUN.POSSESSION, NOUN.FEELING, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, VERB.COGNITION, NOUN.PERSON, VERB.EMOTION, NOUN.PLANT, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.ACT, VERB.CHANGE]</td>\n",
       "      <td>37</td>\n",
       "      <td>118</td>\n",
       "      <td>1014</td>\n",
       "      <td>2242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.TOPS, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.SHAPE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.POSSESSION, NOUN.FEELING, NOUN.POSSESSION, VERB.COMPETITION, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.WEATHER, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE]</td>\n",
       "      <td>40</td>\n",
       "      <td>118</td>\n",
       "      <td>1011</td>\n",
       "      <td>2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Johannsen2014</th>\n",
       "      <th>test</th>\n",
       "      <td>[I, B, O]</td>\n",
       "      <td>[NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.SHAPE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.COMPETITION, VERB.POSSESSION, NOUN.FEELING, NOUN.POSSESSION, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE]</td>\n",
       "      <td>37</td>\n",
       "      <td>200</td>\n",
       "      <td>1249</td>\n",
       "      <td>3064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           boundaries  \\\n",
       "data_key      split_prefix              \n",
       "Ritter        train         [I, B, O]   \n",
       "              dev           [I, B, O]   \n",
       "              test          [I, B, O]   \n",
       "Johannsen2014 test          [I, B, O]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 labels  \\\n",
       "data_key      split_prefix                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "Ritter        train         [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.TOPS, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.POSSESSION, VERB.COMPETITION, NOUN.POSSESSION, NOUN.FEELING, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.WEATHER, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, NOUN.PLANT, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE]   \n",
       "              dev           [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.COMPETITION, VERB.POSSESSION, NOUN.POSSESSION, NOUN.FEELING, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, VERB.COGNITION, NOUN.PERSON, VERB.EMOTION, NOUN.PLANT, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.ACT, VERB.CHANGE]                                          \n",
       "              test          [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.TOPS, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.SHAPE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.POSSESSION, NOUN.FEELING, NOUN.POSSESSION, VERB.COMPETITION, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.WEATHER, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE]   \n",
       "Johannsen2014 test          [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.SHAPE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.COMPETITION, VERB.POSSESSION, NOUN.FEELING, NOUN.POSSESSION, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE]                                         \n",
       "\n",
       "                            labels_unique  sequences  tokens_unique  \\\n",
       "data_key      split_prefix                                            \n",
       "Ritter        train         40             551        3174            \n",
       "              dev           37             118        1014            \n",
       "              test          40             118        1011            \n",
       "Johannsen2014 test          37             200        1249            \n",
       "\n",
       "                            total_tokens  \n",
       "data_key      split_prefix                \n",
       "Ritter        train         10652         \n",
       "              dev           2242          \n",
       "              test          2291          \n",
       "Johannsen2014 test          3064          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llllrrrr}\n",
      "\\toprule\n",
      "              &      & boundaries &                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       labels &  labels\\_unique &  sequences &  tokens\\_unique &  total\\_tokens \\\\\n",
      "data\\_key & split\\_prefix &            &                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              &                &            &                &               \\\\\n",
      "\\midrule\n",
      "Ritter & train &  [I, B, O] &  [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.TOPS, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.POSSESSION, VERB.COMPETITION, NOUN.POSSESSION, NOUN.FEELING, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.WEATHER, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, NOUN.PLANT, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE] &  40 &  551 &  3174 &  10652 \\\\\n",
      "              & dev &  [I, B, O] &  [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.COMPETITION, VERB.POSSESSION, NOUN.POSSESSION, NOUN.FEELING, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, VERB.COGNITION, NOUN.PERSON, VERB.EMOTION, NOUN.PLANT, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.ACT, VERB.CHANGE] &  37 &  118 &  1014 &  2242 \\\\\n",
      "              & test &  [I, B, O] &  [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.TOPS, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.MOTIVE, NOUN.SHAPE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.POSSESSION, NOUN.FEELING, NOUN.POSSESSION, VERB.COMPETITION, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.WEATHER, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE] &  40 &  118 &  1011 &  2291 \\\\\n",
      "Johannsen2014 & test &  [I, B, O] &  [NOUN.BODY, NOUN.STATE, NOUN.ARTIFACT, NOUN.ATTRIBUTE, NOUN.FOOD, NOUN.COGNITION, NOUN.EVENT, NOUN.OBJECT, NOUN.SHAPE, NOUN.GROUP, VERB.COMMUNICATION, NOUN.PHENOMENON, VERB.COMPETITION, VERB.POSSESSION, NOUN.FEELING, NOUN.POSSESSION, VERB.SOCIAL, NOUN.ANIMAL, VERB.CREATION, VERB.CONSUMPTION, VERB.PERCEPTION, VERB.CONTACT, VERB.BODY, NOUN.LOCATION, NOUN.QUANTITY, NOUN.SUBSTANCE, NOUN.RELATION, NOUN.TIME, NOUN.PERSON, VERB.COGNITION, VERB.EMOTION, VERB.STATIVE, VERB.MOTION, NOUN.COMMUNICATION, NOUN.PROCESS, NOUN.ACT, VERB.CHANGE] &  37 &  200 &  1249 &  3064 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stats_data = gather_data(SUPERSENSE_TAGGING_FILES, \"SUPERSENSE\", split_boundary=True, label_idx=2);\n",
    "show_stats(stats_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {
    "height": "712px",
    "left": "0px",
    "right": "1495.11px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "none",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
